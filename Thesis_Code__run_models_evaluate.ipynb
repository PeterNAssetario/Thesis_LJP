{"cells":[{"cell_type":"markdown","metadata":{"id":"a4b5da75-708d-442f-b2e5-a35db4dcd770"},"source":["# Packages:"],"id":"a4b5da75-708d-442f-b2e5-a35db4dcd770"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFNsRyLQkgzL"},"outputs":[],"source":["try:\n","  from google.colab import drive\n","  !nvidia-smi\n","  drive.mount('/content/drive')\n","  path = 'drive/MyDrive/Thesis/'\n","except:\n","  path = './'"],"id":"aFNsRyLQkgzL"},{"cell_type":"code","source":["!pip install keras_preprocessing\n","!pip install transformers\n","import nltk\n","nltk.download('punkt')\n","!pip install lime"],"metadata":{"id":"RaS62pNGDAtP"},"id":"RaS62pNGDAtP","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3d0caca-2f9e-4e45-9f29-de0ddcb91f0b"},"outputs":[],"source":["# Packages for loading data:\n","from os import walk\n","import os\n","import pprint\n","import itertools\n","import json\n","import re\n","import pickle\n","import sys\n","import warnings\n","\n","# Packages for effective data storage / math utils:\n","import pandas as pd\n","import numpy as np\n","\n","# Packages for plotting:\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","\n","# Packages for test train data prep:\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n","\n","# Packages for classical modeling:\n","from sklearn.linear_model import LogisticRegression, Perceptron\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neural_network import MLPClassifier\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","\n","# Packages for deep learning:\n","import keras\n","from keras import backend as K\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, Model\n","from keras.layers import (Embedding, Dense, Flatten, Input, Lambda,\n","                          GlobalMaxPooling1D, MaxPooling1D, Conv1D,\n","                          Bidirectional, GRU, LSTM,\n","                          TimeDistributed, Dropout)\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import to_categorical\n","from nltk.tokenize import sent_tokenize\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.mixed_precision import Policy, set_global_policy\n","\n","# Packages for performance:\n","from sklearn.metrics import (classification_report, confusion_matrix,\n","                             accuracy_score, f1_score, roc_auc_score)\n","\n","# Packages for model interpretation:\n","from lime import lime_text\n","\n","# Misc.:\n","import time\n","import multiprocessing\n","\n","seed = 101\n","cores = multiprocessing.cpu_count()"],"id":"c3d0caca-2f9e-4e45-9f29-de0ddcb91f0b"},{"cell_type":"markdown","metadata":{"id":"QhtHKo8oQZVD"},"source":["# Running Classical models:"],"id":"QhtHKo8oQZVD"},{"cell_type":"markdown","metadata":{"id":"zYtVR-pQzsyf"},"source":["\n","**Function 1:**\n","\n","1. Read in input data/model to use.\n","\n","2. Runs hyperparameter tuning via 5-fold CV on training set with given model and data. Saves optimal hyperparameters and saves best model in a pickle.\n","\n","---------------\n","\n","**Function 2:**\n","\n","3. Predicts test with opt. model.\n","\n","4. Saves confusion matrix.\n","\n","---------------\n","\n","**Classical Models:**\n","\n","* Logistic Regression -\n","* Gaus. Na√Øve Bayes -\n","* SVM -\n","* DT -\n","* RF -\n","* LightGBM -\n","* k-NN -\n","* perceptron (single & multi) -\n","\n","**Deep Learning Models:**\n","\n","* BERT\n","* LSTM\n","* GRU\n","* BiLSTM\n","* CNN\n","* HAN\n","* BERT\n","* Hier-BERT\n","\n","---------------\n","\n","**Input Data:**\n","\n","* Bag-of-ngarms: ngram (1, 1) (+ Truncated SVD) (+ LDA)\n","* Bag-of-ngarms: ngram (1, 2) (+ Truncated SVD) (+ LDA)\n","* TF-IDF: ngram (1, 1) (+ Truncated SVD) (+ LDA)\n","* TF-IDF: ngram (1, 2) (+ Truncated SVD) (+ LDA)"],"id":"zYtVR-pQzsyf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsYuGBTnQYaX"},"outputs":[],"source":["def vec_path_getter(\n","    vecpath : str,\n","    contains : str,\n","):\n","    #########\n","    # Input:\n","    # Output: list of all paths to jasons to be used later\n","    #########\n","\n","    filenames = next(walk(vecpath), (None, None, []))[2]\n","    filenames = [str(vecpath + \"/\" + file) for file in filenames\n","                 if contains in file]\n","\n","    return(filenames)\n","\n","vec_x_paths = vec_path_getter(\n","    path + \"ECHR_Dataset_vec\",\n","    \"x\"\n","    )\n","pattern = r'(?<=vec/)(.*?)(?=_test_x.parquet.gzip|_train_x.parquet.gzip)'\n","unique_datasets = list(set([re.search(pattern, string).group(0) for string in vec_x_paths]))\n","vec_x_paths = [[x for x in vec_x_paths if str(i + \"_train\") in x or str(i + \"_test\") in x] for i in unique_datasets]\n","\n","y_paths = vec_path_getter(\n","    path + \"ECHR_Dataset_clean\",\n","    \"y\"\n","    )\n","\n","classical_models = [\n","    LogisticRegression,\n","    GaussianNB,\n","    SVC,\n","    DecisionTreeClassifier,\n","    RandomForestClassifier,\n","    LGBMClassifier,\n","    KNeighborsClassifier,\n","    Perceptron,\n","    MLPClassifier,\n","    ]\n","params = [\n","    { # LogisticRegression\n","    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n","    'penalty': [None, 'l1', 'l2'],\n","    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n","    },\n","    { # GaussianNB\n","    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n","    },\n","    { # SVC\n","    'C': [0.001, 0.01, 0.1, 1, 10],\n","    'gamma': [1, 0.1, 0.01, 0.001],\n","    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","    },\n","    { # DecisionTreeClassifier\n","    'criterion': ['gini', 'entropy', 'log_loss'],\n","    'max_depth': np.arange(10, 50, 2),\n","    'splitter': ['best', 'random'],\n","    'ccp_alpha': np.arange(0, 0.2, 0.01),\n","    },\n","    { # RandomForestClassifier\n","    'n_estimators': np.arange(10, 200, 10),\n","    'criterion': ['gini', 'entropy', 'log_loss'],\n","    'max_depth': np.arange(10, 50, 2),\n","    'ccp_alpha': np.arange(0, 0.2, 0.01),\n","    },\n","    { # LGBMClassifier\n","    'boosting_type': ['gbdt', 'dart', 'goss'],\n","    'num_leaves': [10, 50, 100, 200],\n","    'max_depth': [5, 10, 15, 20, 50],\n","    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","    'n_estimators': [100, 200, 500, 1000],\n","    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n","    },\n","    { # KNeighborsClassifier\n","    'n_neighbors': np.arange(10, 50, 2),\n","    'weights': ['uniform', 'distance'],\n","    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n","    'p': [1, 2, 3]\n","    },\n","    { # Perceptron\n","    'penalty': [None, 'l1', 'l2', 'elasticnet'],\n","    'alpha': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n","    'max_iter': np.arange(1000, 5000, 1000),\n","    },\n","    { # MLPClassifier\n","    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n","    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n","    'solver': ['lbfgs', 'sgd', 'adam'],\n","    'alpha': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n","    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n","    }\n","    ]"],"id":"UsYuGBTnQYaX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7lNje4DRfUZ"},"outputs":[],"source":["vec_x_paths = [\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_lda_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_lda_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_lda_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_lda_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_lda_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_lda_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_lda_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_lda_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_tsvd_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_uni_tsvd_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_tsvd_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/tfidf_bi_tsvd_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_tsvd_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_uni_tsvd_test_x.parquet.gzip'],\n","    # ['drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_tsvd_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/bow_bi_tsvd_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/w2v_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/w2v_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/d2v_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/d2v_test_x.parquet.gzip'],\n","    #['drive/MyDrive/Thesis/ECHR_Dataset_vec/glove_train_x.parquet.gzip', 'drive/MyDrive/Thesis/ECHR_Dataset_vec/glove_test_x.parquet.gzip'],\n","    ]"],"id":"T7lNje4DRfUZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1XdXAxxBZSh"},"outputs":[],"source":["def hyperparameter_tuning(model, params, x_train, y_train):\n","    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","    clf = RandomizedSearchCV(model(), params, cv=kfold, n_iter=25, n_jobs=None, random_state=42)\n","    search = clf.fit(x_train, y_train)\n","    best_params = search.best_params_\n","    best_model = search.best_estimator_\n","\n","    return best_params, best_model\n","\n","def save_model(best_model, filename):\n","    with open(filename, 'wb') as f:\n","        pickle.dump(best_model, f)\n","\n","def run_models_on_datasets(models, params, datasets_paths):\n","    y_train = pd.read_pickle([i for i in y_paths if 'train' in i][0])\n","    y_test =  pd.read_pickle([i for i in y_paths if 'test'  in i][0])\n","    pattern = r'(?<=vec/)(.*?)(?=_test_x.parquet.gzip|_train_x.parquet.gzip)'\n","\n","    for i, model in enumerate(models):\n","        for j, datasets in enumerate(datasets_paths):\n","            # Set up:\n","            datasets.sort()\n","            temp_model_name = str(model).split('.')[-1].split(\"'\")[0]\n","            temp_data_name = re.search(pattern, datasets[0]).group(0)\n","            print(f\"Running model {temp_model_name} on dataset {temp_data_name}\")\n","\n","            # Read correct data:\n","            x_train = pd.read_parquet(datasets[1])\n","            #x_test  = pd.read_parquet(datasets[0])\n","\n","            # Hypertune:\n","            best_params, best_model = hyperparameter_tuning(model, params[i], x_train, y_train)\n","\n","            # Save best model:\n","            filename = f\"model_{temp_model_name}__dataset_{temp_data_name}\"\n","            save_model(best_model, path + 'ECHR_model/' + filename + '.pkl')\n","\n","            # Done:\n","            print(f\"Best Parameters for model {i+1} on dataset {j+1}: \", best_params)"],"id":"V1XdXAxxBZSh"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKVZ7Bh7nGCh","outputId":"22e40dad-ad01-4f42-df3a-245f69237a7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running model SVC on dataset bow_bi_tsvd\n"]}],"source":["run_models_on_datasets(classical_models, params, vec_x_paths)"],"id":"hKVZ7Bh7nGCh"},{"cell_type":"markdown","metadata":{"id":"S6KI8pRgzkqK"},"source":["# Running DL models:"],"id":"S6KI8pRgzkqK"},{"cell_type":"markdown","metadata":{"id":"4JOwIlSYxy8Z"},"source":["**Deep Learning Models:**\n","\n","* CNN\n","* GRU\n","* HAN\n","* BiLSTM\n","* BERT\n","* Hier-BERT"],"id":"4JOwIlSYxy8Z"},{"cell_type":"code","source":["df_train_x_raw = pd.read_pickle(path + \"ECHR_Dataset_clean/df_train_x.pkl\")\n","df_train_y_raw = pd.read_pickle(path + \"ECHR_Dataset_clean/df_train_y.pkl\")\n","\n","# Create validation split:\n","df_train_all = pd.concat({\"TEXT\": df_train_x_raw, \"new_CONCLUSION\": df_train_y_raw}, axis = 1)\n","df_train, df_val = train_test_split(df_train_all, test_size=0.2, random_state=seed)\n","df_train_x = df_train.TEXT\n","df_train_y = df_train.new_CONCLUSION\n","df_val_x = df_val.TEXT\n","df_val_y = df_val.new_CONCLUSION\n","\n","df_test_x  = pd.read_pickle(path + \"ECHR_Dataset_clean/df_test_x.pkl\")\n","df_test_y  = pd.read_pickle(path + \"ECHR_Dataset_clean/df_test_y.pkl\")\n","\n","df_all_x = pd.concat([df_train_x_raw, df_test_x])\n","df_all_y = pd.concat([df_train_y_raw, df_test_y])"],"metadata":{"id":"8Y7RuYEPEgQJ"},"execution_count":null,"outputs":[],"id":"8Y7RuYEPEgQJ"},{"cell_type":"code","source":["vocab_size = 20000  # Max number of words in the vocabulary\n","embedding_dim = 256 # Dimensions of the embedding space\n","\n","# Preprocessing text data\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(df_train_x)\n","sequences_train = tokenizer.texts_to_sequences(df_train_x)\n","sequences_val = tokenizer.texts_to_sequences(df_val_x)\n","sequences_test = tokenizer.texts_to_sequences(df_test_x)\n","\n","max_len = max(\n","    max([len(i) for i in sequences_train]),\n","    max([len(i) for i in sequences_val]),\n","    max([len(i) for i in sequences_test]),\n","    ) # Max length of each document'\n","\n","token_train_x = pad_sequences(sequences_train, maxlen=max_len)\n","token_val_x = pad_sequences(sequences_val, maxlen=max_len)\n","token_test_x = pad_sequences(sequences_test, maxlen=max_len)"],"metadata":{"id":"Rq-amMxUEgQJ"},"execution_count":null,"outputs":[],"id":"Rq-amMxUEgQJ"},{"cell_type":"code","source":["drop_param = 0.2\n","r_l2_param = l2(0.001)\n","embed_l2_param = l2(0.0001)"],"metadata":{"id":"kX_30JJk2zJ7"},"id":"kX_30JJk2zJ7","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CNN:"],"metadata":{"id":"UsBtoSZC4uQp"},"id":"UsBtoSZC4uQp"},{"cell_type":"code","source":["# Using 3 Conv1D layers followed by max pooling layers\n","model_CNN = Sequential()\n","model_CNN.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_CNN.add(Conv1D(256, 2, activation='relu'))\n","model_CNN.add(MaxPooling1D(2))\n","model_CNN.add(Conv1D(128, 2, activation='relu'))\n","model_CNN.add(MaxPooling1D(2))\n","model_CNN.add(Conv1D(128, 2, activation='relu'))\n","model_CNN.add(MaxPooling1D(4))  # global max pooling\n","# Using the flatten layer to convert into 1D tensor\n","model_CNN.add(Flatten())\n","# passing the output embeddings through 2 dense layers\n","model_CNN.add(Dense(128, activation='relu'))\n","model_CNN.add(Dense(32, activation='relu'))\n","# Using sigmoid classifier\n","model_CNN.add(Dense(1, activation='sigmoid'))\n","\n","model_CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","\n","print(\"Simplified convolutional neural network\")\n","model_CNN.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aICGdLIbEsf9","executionInfo":{"status":"ok","timestamp":1688106322229,"user_tz":-120,"elapsed":2783,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"09f27d4e-ccad-439a-cca1-969934edfd1f"},"id":"aICGdLIbEsf9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Simplified convolutional neural network\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 28659, 256)        5120000   \n","                                                                 \n"," conv1d (Conv1D)             (None, 28658, 256)        131328    \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 14329, 256)       0         \n"," )                                                               \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 14328, 128)        65664     \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 7164, 128)        0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 7163, 128)         32896     \n","                                                                 \n"," max_pooling1d_2 (MaxPooling  (None, 1790, 128)        0         \n"," 1D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 229120)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               29327488  \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 34,681,537\n","Trainable params: 34,681,537\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_CNN.fit(token_train_x, df_train_y,\n","              validation_data=(token_val_x, df_val_y),\n","              epochs=10, verbose=1)\n","\n","model_CNN.save(path + 'ECHR_model/model_cnn__dataset_all.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ip9idExvEuRY","executionInfo":{"status":"ok","timestamp":1688106720078,"user_tz":-120,"elapsed":397404,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"4541758c-3f4a-456f-d12d-3b85b8cea931"},"id":"Ip9idExvEuRY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 70s 278ms/step - loss: 0.6258 - acc: 0.6267 - val_loss: 0.4102 - val_acc: 0.8150\n","Epoch 2/10\n","200/200 [==============================] - 46s 230ms/step - loss: 0.3113 - acc: 0.8687 - val_loss: 0.3061 - val_acc: 0.8727\n","Epoch 3/10\n","200/200 [==============================] - 44s 222ms/step - loss: 0.1481 - acc: 0.9453 - val_loss: 0.3674 - val_acc: 0.8608\n","Epoch 4/10\n","200/200 [==============================] - 39s 197ms/step - loss: 0.0419 - acc: 0.9851 - val_loss: 0.4491 - val_acc: 0.8652\n","Epoch 5/10\n","200/200 [==============================] - 37s 186ms/step - loss: 0.0254 - acc: 0.9909 - val_loss: 0.8635 - val_acc: 0.8533\n","Epoch 6/10\n","200/200 [==============================] - 36s 178ms/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.7579 - val_acc: 0.8489\n","Epoch 7/10\n","200/200 [==============================] - 34s 171ms/step - loss: 0.0194 - acc: 0.9934 - val_loss: 0.7581 - val_acc: 0.8577\n","Epoch 8/10\n","200/200 [==============================] - 29s 148ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.9261 - val_acc: 0.8307\n","Epoch 9/10\n","200/200 [==============================] - 30s 151ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 1.1210 - val_acc: 0.8614\n","Epoch 10/10\n","200/200 [==============================] - 29s 146ms/step - loss: 0.0249 - acc: 0.9923 - val_loss: 0.9152 - val_acc: 0.8558\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTM3rxJixzyK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688106721965,"user_tz":-120,"elapsed":1900,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"39940428-e3ce-47f3-c753-b1686ceea3c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 2s 23ms/step\n","0.8454591068740592\n","0.8453325942350332\n"]}],"source":["y_pred = (model_CNN.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"id":"GTM3rxJixzyK"},{"cell_type":"code","source":["# reg CNN:\n","model_reg_CNN = Sequential()\n","model_reg_CNN.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_reg_CNN.add(Conv1D(256, 2, activation='relu',\n","                         kernel_regularizer = r_l2_param))\n","model_reg_CNN.add(MaxPooling1D(2))\n","model_reg_CNN.add(Conv1D(128, 2, activation='relu',\n","                         kernel_regularizer = r_l2_param))\n","model_reg_CNN.add(MaxPooling1D(2))\n","model_reg_CNN.add(Conv1D(128, 2, activation='relu',\n","                         kernel_regularizer = r_l2_param))\n","model_reg_CNN.add(MaxPooling1D(4))\n","model_reg_CNN.add(Flatten())\n","model_reg_CNN.add(Dense(128, activation='relu'))\n","model_reg_CNN.add(Dense(32, activation='relu'))\n","model_reg_CNN.add(Dense(1, activation='sigmoid'))\n","\n","model_reg_CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","model_reg_CNN.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_8lx3EK2UIL","executionInfo":{"status":"ok","timestamp":1688121770013,"user_tz":-120,"elapsed":8,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"2682cd2b-b878-4620-acc5-ca2f2520ceec"},"id":"X_8lx3EK2UIL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_6 (Embedding)     (None, 28659, 256)        5120000   \n","                                                                 \n"," conv1d_10 (Conv1D)          (None, 28658, 256)        131328    \n","                                                                 \n"," max_pooling1d_9 (MaxPooling  (None, 14329, 256)       0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_11 (Conv1D)          (None, 14328, 128)        65664     \n","                                                                 \n"," max_pooling1d_10 (MaxPoolin  (None, 7164, 128)        0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_12 (Conv1D)          (None, 7163, 128)         32896     \n","                                                                 \n"," max_pooling1d_11 (MaxPoolin  (None, 1790, 128)        0         \n"," g1D)                                                            \n","                                                                 \n"," flatten_3 (Flatten)         (None, 229120)            0         \n","                                                                 \n"," dense_9 (Dense)             (None, 128)               29327488  \n","                                                                 \n"," dense_10 (Dense)            (None, 32)                4128      \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 34,681,537\n","Trainable params: 34,681,537\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_reg_CNN.fit(token_train_x, df_train_y,\n","                  validation_data=(token_val_x, df_val_y),\n","                  epochs=10, verbose=1)\n","\n","y_pred = (model_reg_CNN.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"149ABTz72c5B","executionInfo":{"status":"ok","timestamp":1688122133266,"user_tz":-120,"elapsed":361686,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"66a4cd80-e24d-42a6-8b16-253effb46131"},"id":"149ABTz72c5B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 50s 238ms/step - loss: 0.8991 - acc: 0.5420 - val_loss: 0.7620 - val_acc: 0.5962\n","Epoch 2/10\n","200/200 [==============================] - 44s 218ms/step - loss: 0.6345 - acc: 0.7069 - val_loss: 0.4882 - val_acc: 0.8025\n","Epoch 3/10\n","200/200 [==============================] - 41s 205ms/step - loss: 0.3536 - acc: 0.8712 - val_loss: 0.5216 - val_acc: 0.7680\n","Epoch 4/10\n","200/200 [==============================] - 40s 198ms/step - loss: 0.1900 - acc: 0.9404 - val_loss: 0.6847 - val_acc: 0.8044\n","Epoch 5/10\n","200/200 [==============================] - 37s 185ms/step - loss: 0.1117 - acc: 0.9722 - val_loss: 0.7111 - val_acc: 0.7956\n","Epoch 6/10\n","200/200 [==============================] - 34s 172ms/step - loss: 0.0601 - acc: 0.9904 - val_loss: 0.9965 - val_acc: 0.7956\n","Epoch 7/10\n","200/200 [==============================] - 31s 156ms/step - loss: 0.0567 - acc: 0.9900 - val_loss: 1.0484 - val_acc: 0.7969\n","Epoch 8/10\n","200/200 [==============================] - 30s 152ms/step - loss: 0.0883 - acc: 0.9793 - val_loss: 1.1947 - val_acc: 0.7843\n","Epoch 9/10\n","200/200 [==============================] - 27s 135ms/step - loss: 0.0448 - acc: 0.9942 - val_loss: 0.9804 - val_acc: 0.7962\n","Epoch 10/10\n","200/200 [==============================] - 27s 135ms/step - loss: 0.0374 - acc: 0.9961 - val_loss: 1.4598 - val_acc: 0.8013\n","63/63 [==============================] - 1s 14ms/step\n","0.7907676869041645\n","0.7906023639218092\n"]}]},{"cell_type":"markdown","source":["## GRU:"],"metadata":{"id":"N3MbEDX8Xf7A"},"id":"N3MbEDX8Xf7A"},{"cell_type":"code","source":["model_GRU = Sequential()\n","\n","model_GRU.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_GRU.add(GRU(32, activation = 'tanh', recurrent_activation = 'sigmoid')) # these two options allow for GPU computation\n","model_GRU.add(Dense(32, activation='relu'))\n","model_GRU.add(Dense(16, activation='relu'))\n","# Using sigmoid classifier\n","model_GRU.add(Dense(1, activation='sigmoid'))\n","\n","model_GRU.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","\n","model_GRU.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YSe0NmDzc_i","executionInfo":{"status":"ok","timestamp":1688106722513,"user_tz":-120,"elapsed":551,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"c35aa29a-9a84-4d6c-8815-0ddeb2374a74"},"id":"8YSe0NmDzc_i","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 28659, 256)        5120000   \n","                                                                 \n"," gru (GRU)                   (None, 32)                27840     \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                1056      \n","                                                                 \n"," dense_4 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 5,149,441\n","Trainable params: 5,149,441\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_GRU.fit(token_train_x, df_train_y,\n","              validation_data=(token_val_x, df_val_y),\n","              epochs=10, verbose=1)\n","\n","model_GRU.save(path + 'ECHR_model/model_gru__dataset_all.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mt78ZN2L51IX","executionInfo":{"status":"ok","timestamp":1688108274925,"user_tz":-120,"elapsed":1552416,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"026adf4e-90cd-4813-d555-32e61558d851"},"id":"mt78ZN2L51IX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 170s 832ms/step - loss: 0.6729 - acc: 0.5620 - val_loss: 0.6338 - val_acc: 0.6320\n","Epoch 2/10\n","200/200 [==============================] - 162s 810ms/step - loss: 0.5438 - acc: 0.7175 - val_loss: 0.6237 - val_acc: 0.6351\n","Epoch 3/10\n","200/200 [==============================] - 160s 803ms/step - loss: 0.3665 - acc: 0.8353 - val_loss: 0.7766 - val_acc: 0.6395\n","Epoch 4/10\n","200/200 [==============================] - 156s 782ms/step - loss: 0.2339 - acc: 0.9043 - val_loss: 0.9262 - val_acc: 0.6245\n","Epoch 5/10\n","200/200 [==============================] - 156s 779ms/step - loss: 0.1441 - acc: 0.9435 - val_loss: 1.1458 - val_acc: 0.6270\n","Epoch 6/10\n","200/200 [==============================] - 152s 761ms/step - loss: 0.0954 - acc: 0.9628 - val_loss: 1.5413 - val_acc: 0.6458\n","Epoch 7/10\n","200/200 [==============================] - 150s 748ms/step - loss: 0.0708 - acc: 0.9732 - val_loss: 1.7091 - val_acc: 0.6351\n","Epoch 8/10\n","200/200 [==============================] - 150s 752ms/step - loss: 0.0403 - acc: 0.9816 - val_loss: 2.0189 - val_acc: 0.6389\n","Epoch 9/10\n","200/200 [==============================] - 150s 748ms/step - loss: 0.0330 - acc: 0.9851 - val_loss: 2.0654 - val_acc: 0.6395\n","Epoch 10/10\n","200/200 [==============================] - 146s 728ms/step - loss: 0.0335 - acc: 0.9843 - val_loss: 2.4117 - val_acc: 0.6389\n"]}]},{"cell_type":"code","source":["y_pred = (model_GRU.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-M7FeZZy6Lw7","executionInfo":{"status":"ok","timestamp":1688108299910,"user_tz":-120,"elapsed":17735,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"54038afc-c83e-4bc1-8ab5-6474b2422273"},"id":"-M7FeZZy6Lw7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 17s 263ms/step\n","0.6347215253386854\n","0.6344011240326486\n"]}]},{"cell_type":"code","source":["model_reg_GRU = Sequential()\n","model_reg_GRU.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_reg_GRU.add(GRU(32, activation = 'tanh', recurrent_activation = 'sigmoid',\n","                      dropout = drop_param,\n","                      kernel_regularizer = r_l2_param)) # these two options allow for GPU computation\n","model_reg_GRU.add(Dense(32, activation='relu'))\n","model_reg_GRU.add(Dense(16, activation='relu'))\n","model_reg_GRU.add(Dense(1, activation='sigmoid'))\n","\n","model_reg_GRU.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","model_reg_GRU.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNdLpWqE6EzY","executionInfo":{"status":"ok","timestamp":1688124367615,"user_tz":-120,"elapsed":508,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"8b47c2ce-cee8-4cee-aac1-59bf6cfe6514"},"id":"XNdLpWqE6EzY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_4 (Embedding)     (None, 28659, 256)        5120000   \n","                                                                 \n"," gru_3 (GRU)                 (None, 32)                27840     \n","                                                                 \n"," dense_9 (Dense)             (None, 32)                1056      \n","                                                                 \n"," dense_10 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_11 (Dense)            (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 5,149,441\n","Trainable params: 5,149,441\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_reg_GRU.fit(token_train_x, df_train_y,\n","                  validation_data=(token_val_x, df_val_y),\n","                  epochs=10, verbose=1)\n","\n","y_pred = (model_reg_GRU.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbmLWIcs6HSb","executionInfo":{"status":"ok","timestamp":1688125999074,"user_tz":-120,"elapsed":1630475,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"fe06cc04-bcb3-4bcc-baf0-be5e73d0ea6b"},"id":"TbmLWIcs6HSb","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 178s 875ms/step - loss: 0.7052 - acc: 0.5778 - val_loss: 0.6320 - val_acc: 0.6564\n","Epoch 2/10\n","200/200 [==============================] - 170s 849ms/step - loss: 0.5313 - acc: 0.7362 - val_loss: 0.6149 - val_acc: 0.6752\n","Epoch 3/10\n","200/200 [==============================] - 166s 829ms/step - loss: 0.3693 - acc: 0.8424 - val_loss: 0.7191 - val_acc: 0.6633\n","Epoch 4/10\n","200/200 [==============================] - 164s 818ms/step - loss: 0.2336 - acc: 0.9126 - val_loss: 0.8618 - val_acc: 0.6690\n","Epoch 5/10\n","200/200 [==============================] - 160s 801ms/step - loss: 0.1627 - acc: 0.9443 - val_loss: 1.0195 - val_acc: 0.6508\n","Epoch 6/10\n","200/200 [==============================] - 159s 797ms/step - loss: 0.1246 - acc: 0.9581 - val_loss: 1.1251 - val_acc: 0.6646\n","Epoch 7/10\n","200/200 [==============================] - 156s 783ms/step - loss: 0.0845 - acc: 0.9733 - val_loss: 1.4903 - val_acc: 0.6564\n","Epoch 8/10\n","200/200 [==============================] - 154s 771ms/step - loss: 0.0719 - acc: 0.9787 - val_loss: 1.5311 - val_acc: 0.6458\n","Epoch 9/10\n","200/200 [==============================] - 153s 765ms/step - loss: 0.0649 - acc: 0.9784 - val_loss: 1.7316 - val_acc: 0.6589\n","Epoch 10/10\n","200/200 [==============================] - 155s 773ms/step - loss: 0.0421 - acc: 0.9868 - val_loss: 1.8047 - val_acc: 0.6652\n","63/63 [==============================] - 17s 260ms/step\n","0.6643251379829402\n","0.6641759974409898\n"]}]},{"cell_type":"markdown","source":["## HAN:"],"metadata":{"id":"Ppg1JorK6Xwe"},"id":"Ppg1JorK6Xwe"},{"cell_type":"markdown","source":["### Backend:"],"metadata":{"id":"r0bj6z_VXDir"},"id":"r0bj6z_VXDir"},{"cell_type":"code","source":["class AttentionLayer(keras.layers.Layer):\n","    def __init__(self, context_vector_length=100, **kwargs):\n","        \"\"\"\n","        An implementation of a attention layer. This layer\n","        accepts a 3d Tensor (batch_size, time_steps, input_dim) and\n","        applies a single layer attention mechanism in the time\n","        direction (the second axis).\n","        :param context_vector_lenght: (int) The size of the hidden context vector.\n","            If set to 1 this layer reduces to a standard attention layer.\n","        :param kwargs: Any argument that the baseclass Layer accepts.\n","        \"\"\"\n","        self.context_vector_length = context_vector_length\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        dim = input_shape[2]\n","\n","        # Add a weights layer for the\n","        self.W = self.add_weight(\n","            name='W', shape=(dim, self.context_vector_length),\n","            initializer=keras.initializers.get('uniform'),\n","            trainable=True\n","        )\n","\n","        self.u = self.add_weight(\n","            name='context_vector', shape=(self.context_vector_length, 1),\n","            initializer=keras.initializers.get('uniform'),\n","            trainable=True\n","        )\n","\n","        super(AttentionLayer, self).build(input_shape)\n","\n","    def _get_attention_weights(self, X):\n","        \"\"\"\n","        Computes the attention weights for each timestep in X\n","        :param X: 3d-tensor (batch_size, time_steps, input_dim)\n","        :return: 2d-tensor (batch_size, time_steps) of attention weights\n","        \"\"\"\n","        # Compute a time-wise stimulus, i.e. a stimulus for each\n","        # time step. For this first compute a hidden layer of\n","        # dimension self.context_vector_length and take the\n","        # similarity of this layer with self.u as the stimulus\n","        u_tw = K.tanh(K.dot(X, self.W))\n","        tw_stimulus = K.dot(u_tw, self.u)\n","\n","        # Remove the last axis an apply softmax to the stimulus to\n","        # get a probability.\n","        tw_stimulus = K.reshape(tw_stimulus, (-1, tw_stimulus.shape[1]))\n","        att_weights = K.softmax(tw_stimulus)\n","\n","        return att_weights\n","\n","    def call(self, X):\n","        att_weights = self._get_attention_weights(X)\n","\n","        # Reshape the attention weights to match the dimensions of X\n","        att_weights = K.reshape(att_weights, (-1, att_weights.shape[1], 1))\n","        att_weights = K.repeat_elements(att_weights, X.shape[-1], -1)\n","\n","        # Multiply each input by its attention weights\n","        weighted_input = keras.layers.Multiply()([X, att_weights])\n","\n","        # Sum in the direction of the time-axis.\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[2]\n","\n","    def get_config(self):\n","        config = {\n","            'context_vector_length': self.context_vector_length\n","        }\n","        base_config = super(AttentionLayer, self).get_config()\n","        return {**base_config, **config}"],"metadata":{"id":"1v5IX0jfLpM9"},"id":"1v5IX0jfLpM9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HAN(Model):\n","    def __init__(\n","            self, max_words, max_sentences, output_size,\n","            embedding_matrix, word_encoding_dim=200,\n","            sentence_encoding_dim=200, inputs=None,\n","            outputs=None, name='han-for-docla'\n","    ):\n","        \"\"\"\n","        A Keras implementation of Hierarchical Attention networks\n","        for document classification.\n","        :param max_words: The maximum number of words per sentence\n","        :param max_sentences: The maximum number of sentences\n","        :param output_size: The dimension of the last layer (i.e.\n","            the number of classes you wish to predict)\n","        :param embedding_matrix: The embedding matrix to use for\n","            representing words\n","        :param word_encoding_dim: The dimension of the GRU\n","            layer in the word encoder.\n","        :param sentence_encoding_dim: The dimension of the GRU\n","            layer in the sentence encoder.\n","        \"\"\"\n","        self.max_words = max_words\n","        self.max_sentences = max_sentences\n","        self.output_size = output_size\n","        self.embedding_matrix = embedding_matrix\n","        self.word_encoding_dim = word_encoding_dim\n","        self.sentence_encoding_dim = sentence_encoding_dim\n","\n","        in_tensor, out_tensor = self._build_network()\n","\n","        super(HAN, self).__init__(\n","            inputs=in_tensor, outputs=out_tensor, name=name\n","        )\n","\n","    def build_word_encoder(self, max_words, embedding_matrix, encoding_dim=200):\n","        \"\"\"\n","        Build the model that embeds and encodes in context the\n","        words used in a sentence. The return model takes a tensor of shape\n","        (batch_size, max_length) that represents a collection of sentences\n","        and returns an encoded representation of these sentences.\n","        :param max_words: (int) The maximum sentence length this model accepts\n","        :param embedding_matrix: (2d array-like) A matrix with the i-th row\n","            representing the embedding of the word represented by index i.\n","        :param encoding_dim: (int, should be even) The dimension of the\n","            bidirectional encoding layer. Half of the nodes are used in the\n","            forward direction and half in the backward direction.\n","        :return: Instance of keras.Model\n","        \"\"\"\n","        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n","\n","        vocabulary_size = embedding_matrix.shape[0]\n","        embedding_dim = embedding_matrix.shape[1]\n","\n","        embedding_layer = Embedding(\n","            vocabulary_size, embedding_dim,\n","            weights=[embedding_matrix], input_length=max_words,\n","            trainable=False\n","        )\n","\n","        sentence_input = Input(shape=(max_words,), dtype='int32')\n","        embedded_sentences = embedding_layer(sentence_input)\n","        encoded_sentences = Bidirectional(\n","            GRU(int(encoding_dim / 2), return_sequences=True)\n","        )(embedded_sentences)\n","\n","        return Model(\n","            inputs=[sentence_input], outputs=[encoded_sentences], name='word_encoder'\n","        )\n","\n","    def build_sentence_encoder(self, max_sentences, summary_dim, encoding_dim=200):\n","        \"\"\"\n","        Build the encoder that encodes the vector representation of\n","        sentences in their context.\n","        :param max_sentences: The maximum number of sentences that can be\n","            passed. Use zero-padding to supply shorter sentences.\n","        :param summary_dim: (int) The dimension of the vectors that summarizes\n","            sentences. Should be equal to the encoding_dim of the word\n","            encoder.\n","        :param encoding_dim: (int, even) The dimension of the vector that\n","            summarizes sentences in context. Half is used in forward direction,\n","            half in backward direction.\n","        :return: Instance of keras.Model\n","        \"\"\"\n","        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n","\n","        text_input = Input(shape=(max_sentences, summary_dim))\n","        encoded_sentences = Bidirectional(\n","            GRU(int(encoding_dim / 2), return_sequences=True)\n","        )(text_input)\n","        return Model(\n","            inputs=[text_input], outputs=[encoded_sentences], name='sentence_encoder'\n","        )\n","\n","    def _build_network(self):\n","        \"\"\"\n","        Build the graph that represents this network\n","        :return: in_tensor, out_tensor, Tensors representing the input and output\n","            of this network.\n","        \"\"\"\n","        in_tensor = Input(shape=(self.max_sentences, self.max_words))\n","\n","        word_encoder = self.build_word_encoder(\n","            self.max_words, self.embedding_matrix, self.word_encoding_dim\n","        )\n","\n","        word_rep = TimeDistributed(\n","            word_encoder, name='word_encoder'\n","        )(in_tensor)\n","\n","        # Sentence Rep is a 3d-tensor (batch_size, max_sentences, word_encoding_dim)\n","        sentence_rep = TimeDistributed(\n","            AttentionLayer(), name='word_attention'\n","        )(word_rep)\n","\n","        doc_rep = self.build_sentence_encoder(\n","            self.max_sentences, self.word_encoding_dim, self.sentence_encoding_dim\n","        )(sentence_rep)\n","\n","        # We get the final representation by applying our attention mechanism\n","        # to the encoded sentences\n","        doc_summary = AttentionLayer(name='sentence_attention')(doc_rep)\n","\n","        out_tensor = Dense(\n","            self.output_size, activation='softmax', name='class_prediction'\n","        )(doc_summary)\n","\n","        return in_tensor, out_tensor\n","\n","    def get_config(self):\n","        config = {\n","            'max_words': self.max_words,\n","            'max_sentences': self.max_sentences,\n","            'output_size': self.output_size,\n","            'embedding_matrix': self.embedding_matrix,\n","            'word_encoding_dim': self.word_encoding_dim,\n","            'sentence_encoding_dim': self.sentence_encoding_dim,\n","            'base_config': super(HAN, self).get_config()\n","        }\n","\n","        return config\n","\n","    @classmethod\n","    def from_config(cls, config, custom_objects=None):\n","        \"\"\"\n","        Keras' API isn't really extendible at this point\n","        therefore we need to use a bit hacky solution to\n","        be able to correctly reconstruct the HAN model\n","        from a config. This therefore does not reconstruct\n","        a instance of HAN model, but actually a standard\n","        Keras model that behaves exactly the same.\n","        \"\"\"\n","        base_config = config.pop('base_config')\n","\n","        return Model.from_config(\n","            base_config, custom_objects=custom_objects\n","        )\n","\n","    def predict_sentence_attention(self, X):\n","        \"\"\"\n","        For a given set of texts predict the attention\n","        weights for each sentence.\n","        :param X: 3d-tensor, similar to the input for predict\n","        :return: 2d array (num_obs, max_sentences) containing\n","            the attention weights for each sentence\n","        \"\"\"\n","        att_layer = self.get_layer('sentence_attention')\n","        prev_tensor = att_layer.input\n","\n","        # Create a temporary dummy layer to hold the\n","        # attention weights tensor\n","        dummy_layer = Lambda(\n","            lambda x: att_layer._get_attention_weights(x)\n","        )(prev_tensor)\n","\n","        return Model(self.input, dummy_layer).predict(X)"],"metadata":{"id":"lxQ78odxLSN6"},"id":"lxQ78odxLSN6","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run:"],"metadata":{"id":"xaGp0Wt1XIXA"},"id":"xaGp0Wt1XIXA"},{"cell_type":"code","source":["MAX_WORDS_PER_SENT = 200\n","MAX_SENT = 20\n","MAX_VOC_SIZE = 20000\n","GLOVE_DIM = 100\n","TEST_SPLIT = 0.2"],"metadata":{"id":"XpZtbtwzK3nG"},"id":"XpZtbtwzK3nG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NOT ORIGNAL!\n","\n","#####################################################\n","# Tokenization                                      #\n","#####################################################\n","# Build a Keras Tokenizer that can encode every token\n","word_tokenizer = Tokenizer(num_words=MAX_VOC_SIZE)\n","word_tokenizer.fit_on_texts(df_all_x)\n","\n","# Construct the input matrix. This should be a nd-array of\n","# shape (n_samples, MAX_SENT, MAX_WORDS_PER_SENT).\n","# We zero-pad this matrix (this does not influence\n","# any predictions due to the attention mechanism.\n","X = np.zeros((len(df_all_x), MAX_SENT, MAX_WORDS_PER_SENT), dtype='int32')\n","\n","for i, text in enumerate(df_all_x):\n","    sentences = sent_tokenize(text)\n","    tokenized_sentences = word_tokenizer.texts_to_sequences(\n","        sentences\n","    )\n","    tokenized_sentences = pad_sequences(\n","        tokenized_sentences, maxlen=MAX_WORDS_PER_SENT\n","    )\n","\n","    pad_size = MAX_SENT - tokenized_sentences.shape[0]\n","\n","    if pad_size < 0:\n","        tokenized_sentences = tokenized_sentences[0:MAX_SENT]\n","    else:\n","        tokenized_sentences = np.pad(\n","            tokenized_sentences, ((0, pad_size), (0, 0)),\n","            mode='constant', constant_values=0\n","        )\n","\n","    # Store this observation as the i-th observation in\n","    # the data matrix\n","    X[i] = tokenized_sentences[None, ...]\n","\n","# Transform the labels into a format Keras can handle\n","y = to_categorical(df_all_y)\n","\n","# We make a train/test split\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state = seed)\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state = seed)"],"metadata":{"id":"tKDY0qFnK3sJ"},"id":"tKDY0qFnK3sJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####################################################\n","# Word Embeddings                                   #\n","#####################################################\n","# Now, we need to build the embedding matrix. For this we use\n","# a pretrained (on the wikipedia corpus) 100-dimensional GloVe\n","# model.\n","\n","# Load the embeddings from a file\n","embeddings = {}\n","with open(path + 'glove.6B.100d.txt', encoding='utf-8') as file:\n","    for line in file:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","\n","        embeddings[word] = coefs\n","\n","# Initialize a matrix to hold the word embeddings\n","embedding_matrix = np.random.random(\n","    (len(word_tokenizer.word_index) + 1, GLOVE_DIM)\n",")\n","\n","# Let the padded indices map to zero-vectors. This will\n","# prevent the padding from influencing the results\n","embedding_matrix[0] = 0\n","\n","# Loop though all the words in the word_index and where possible\n","# replace the random initalization with the GloVe vector.\n","for word, index in word_tokenizer.word_index.items():\n","    embedding_vector = embeddings.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[index] = embedding_vector"],"metadata":{"id":"o4ttXbMnK3ug"},"id":"o4ttXbMnK3ug","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####################################################\n","# Model Training                                    #\n","#####################################################\n","model_HAN = HAN(\n","    MAX_WORDS_PER_SENT, MAX_SENT, 2, embedding_matrix,\n","    word_encoding_dim=100, sentence_encoding_dim=100\n",")\n","\n","model_HAN.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['acc'])\n","\n","model_HAN.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRntF325K3wd","executionInfo":{"status":"ok","timestamp":1688108462503,"user_tz":-120,"elapsed":2391,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"d141527d-f9f5-4b56-d715-5331807fda0c"},"id":"aRntF325K3wd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"han-for-docla\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20, 200)]         0         \n","                                                                 \n"," word_encoder (TimeDistribut  (None, 20, 200, 100)     15152100  \n"," ed)                                                             \n","                                                                 \n"," word_attention (TimeDistrib  (None, 20, 100)          10100     \n"," uted)                                                           \n","                                                                 \n"," sentence_encoder (Functiona  (None, 20, 100)          45600     \n"," l)                                                              \n","                                                                 \n"," sentence_attention (Attenti  (None, 100)              10100     \n"," onLayer)                                                        \n","                                                                 \n"," class_prediction (Dense)    (None, 2)                 202       \n","                                                                 \n","=================================================================\n","Total params: 15,218,102\n","Trainable params: 111,602\n","Non-trainable params: 15,106,500\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_HAN.fit(X_train, y_train,\n","              validation_data=(X_val, y_val),\n","              epochs=10, verbose=1)\n","\n","model_HAN.save(path + 'ECHR_model/model_han__dataset_all.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1I1INBYK3yw","executionInfo":{"status":"ok","timestamp":1688108551975,"user_tz":-120,"elapsed":89476,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"7d2dcb78-28fc-47a4-92e4-0c4853d6b934"},"id":"U1I1INBYK3yw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 17s 42ms/step - loss: 0.6929 - acc: 0.5166 - val_loss: 0.6930 - val_acc: 0.4940\n","Epoch 2/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6929 - acc: 0.5064 - val_loss: 0.6930 - val_acc: 0.4940\n","Epoch 3/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6929 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 4/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6929 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 5/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6929 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 6/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6928 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 7/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6928 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 8/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6928 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 9/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6928 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n","Epoch 10/10\n","200/200 [==============================] - 7s 34ms/step - loss: 0.6928 - acc: 0.5067 - val_loss: 0.6931 - val_acc: 0.4940\n"]}]},{"cell_type":"code","source":["y_pred = (model_HAN.predict(X_test) > 0.5).astype(\"int32\")\n","print(accuracy_score(y_test, y_pred))\n","print(f1_score(y_test, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voXIpF9tK30Y","executionInfo":{"status":"ok","timestamp":1688108555924,"user_tz":-120,"elapsed":3965,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"fae9ab71-3ff6-4017-b978-a078dd6eacd4"},"id":"voXIpF9tK30Y","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 3s 9ms/step\n","0.48319116909182136\n","0.3257780784844384\n"]}]},{"cell_type":"markdown","source":["## LSTM:"],"metadata":{"id":"x26EQWJK6a5n"},"id":"x26EQWJK6a5n"},{"cell_type":"code","source":["model_LSTM = Sequential()\n","\n","model_LSTM.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_LSTM.add(LSTM(128, return_sequences=True))\n","model_LSTM.add(LSTM(128))\n","model_LSTM.add(Dense(64,activation='relu'))\n","model_LSTM.add(Dense(16,activation='relu'))\n","model_LSTM.add(Dense(1,activation='sigmoid'))\n","\n","model_LSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","\n","model_LSTM.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLiS2qQC6XGU","executionInfo":{"status":"ok","timestamp":1688108555924,"user_tz":-120,"elapsed":20,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"111098b9-714c-468d-f306-a4d26f39ee87"},"id":"GLiS2qQC6XGU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 28659, 256)        5120000   \n","                                                                 \n"," lstm (LSTM)                 (None, 28659, 128)        197120    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_7 (Dense)             (None, 16)                1040      \n","                                                                 \n"," dense_8 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 5,458,017\n","Trainable params: 5,458,017\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_LSTM.fit(token_train_x, df_train_y,\n","               validation_data=(token_val_x, df_val_y),\n","               epochs=10, verbose=1)\n","\n","model_LSTM.save(path + 'ECHR_model/model_lstm__dataset_all.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvDcT5k57Pxr","executionInfo":{"status":"ok","timestamp":1688111834499,"user_tz":-120,"elapsed":3278591,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"1cb28e91-b833-47ae-9f93-3343d00acd37"},"id":"KvDcT5k57Pxr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 342s 2s/step - loss: 0.6510 - acc: 0.6226 - val_loss: 0.5807 - val_acc: 0.6828\n","Epoch 2/10\n","200/200 [==============================] - 334s 2s/step - loss: 0.4794 - acc: 0.7704 - val_loss: 0.7236 - val_acc: 0.6859\n","Epoch 3/10\n","200/200 [==============================] - 333s 2s/step - loss: 0.3014 - acc: 0.8755 - val_loss: 0.8096 - val_acc: 0.6564\n","Epoch 4/10\n","200/200 [==============================] - 327s 2s/step - loss: 0.1683 - acc: 0.9359 - val_loss: 1.0976 - val_acc: 0.6746\n","Epoch 5/10\n","200/200 [==============================] - 328s 2s/step - loss: 0.1124 - acc: 0.9580 - val_loss: 1.3109 - val_acc: 0.6658\n","Epoch 6/10\n","200/200 [==============================] - 325s 2s/step - loss: 0.0835 - acc: 0.9677 - val_loss: 1.2492 - val_acc: 0.6445\n","Epoch 7/10\n","200/200 [==============================] - 324s 2s/step - loss: 0.0631 - acc: 0.9754 - val_loss: 1.6623 - val_acc: 0.6395\n","Epoch 8/10\n","200/200 [==============================] - 323s 2s/step - loss: 0.0612 - acc: 0.9718 - val_loss: 1.7186 - val_acc: 0.6527\n","Epoch 9/10\n","200/200 [==============================] - 322s 2s/step - loss: 0.0527 - acc: 0.9768 - val_loss: 1.5541 - val_acc: 0.6470\n","Epoch 10/10\n","200/200 [==============================] - 322s 2s/step - loss: 0.0728 - acc: 0.9694 - val_loss: 1.4596 - val_acc: 0.6508\n"]}]},{"cell_type":"code","source":["y_pred = (model_LSTM.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1vhq2f46lUU","executionInfo":{"status":"ok","timestamp":1688111871221,"user_tz":-120,"elapsed":36738,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"38627f3d-d5a0-4739-ae1a-4d23b90527a2"},"id":"U1vhq2f46lUU","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 37s 577ms/step\n","0.6482689412945308\n","0.6481272017346149\n"]}]},{"cell_type":"code","source":["model_reg_LSTM = Sequential()\n","model_reg_LSTM.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model_reg_LSTM.add(LSTM(128, return_sequences=True,\n","                    dropout = 0.25,\n","                    kernel_regularizer = r_l2_param))\n","model_reg_LSTM.add(LSTM(128,\n","                    dropout = drop_param,\n","                    kernel_regularizer = r_l2_param))\n","model_reg_LSTM.add(Dense(64,activation='relu'))\n","model_reg_LSTM.add(Dense(16,activation='relu'))\n","model_reg_LSTM.add(Dense(1,activation='sigmoid'))\n","\n","model_reg_LSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","\n","model_reg_LSTM.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_hVUcZ3K4yA","executionInfo":{"status":"ok","timestamp":1688129710183,"user_tz":-120,"elapsed":1165,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"ad0c6c6c-09b8-40b7-dd5d-3b3d36323c41"},"id":"4_hVUcZ3K4yA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_7 (Embedding)     (None, 28659, 256)        5120000   \n","                                                                 \n"," lstm_4 (LSTM)               (None, 28659, 128)        197120    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dense_18 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_19 (Dense)            (None, 16)                1040      \n","                                                                 \n"," dense_20 (Dense)            (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 5,458,017\n","Trainable params: 5,458,017\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_reg_LSTM.fit(token_train_x, df_train_y,\n","                   validation_data=(token_val_x, df_val_y),\n","                   epochs=10, verbose=1)\n","\n","y_pred = (model_reg_LSTM.predict(token_test_x) > 0.5).astype(\"int32\")\n","print(accuracy_score(df_test_y, y_pred))\n","print(f1_score(df_test_y, y_pred, average='macro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AwlgCfDK4i6","executionInfo":{"status":"ok","timestamp":1688133148130,"user_tz":-120,"elapsed":3437952,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"c30a2b91-f0ef-43f4-c476-e6f579c57880"},"id":"5AwlgCfDK4i6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","200/200 [==============================] - 355s 2s/step - loss: 0.7298 - acc: 0.6247 - val_loss: 0.5981 - val_acc: 0.6897\n","Epoch 2/10\n","200/200 [==============================] - 347s 2s/step - loss: 0.5127 - acc: 0.7625 - val_loss: 0.5938 - val_acc: 0.6809\n","Epoch 3/10\n","200/200 [==============================] - 344s 2s/step - loss: 0.3820 - acc: 0.8483 - val_loss: 0.7008 - val_acc: 0.6915\n","Epoch 4/10\n","200/200 [==============================] - 343s 2s/step - loss: 0.2945 - acc: 0.8954 - val_loss: 0.7466 - val_acc: 0.6533\n","Epoch 5/10\n","200/200 [==============================] - 339s 2s/step - loss: 0.2195 - acc: 0.9315 - val_loss: 0.9890 - val_acc: 0.6690\n","Epoch 6/10\n","200/200 [==============================] - 337s 2s/step - loss: 0.1617 - acc: 0.9489 - val_loss: 1.0690 - val_acc: 0.6614\n","Epoch 7/10\n","200/200 [==============================] - 336s 2s/step - loss: 0.1278 - acc: 0.9630 - val_loss: 1.0008 - val_acc: 0.6533\n","Epoch 8/10\n","200/200 [==============================] - 333s 2s/step - loss: 0.0990 - acc: 0.9741 - val_loss: 1.3472 - val_acc: 0.6495\n","Epoch 9/10\n","200/200 [==============================] - 334s 2s/step - loss: 0.0958 - acc: 0.9738 - val_loss: 1.2764 - val_acc: 0.6451\n","Epoch 10/10\n","200/200 [==============================] - 330s 2s/step - loss: 0.0921 - acc: 0.9741 - val_loss: 1.4971 - val_acc: 0.6376\n","63/63 [==============================] - 38s 598ms/step\n","0.6588058203712995\n","0.6587748080916729\n"]}]},{"cell_type":"markdown","source":["## BERT:"],"metadata":{"id":"HtBFv7YI7emc"},"id":"HtBFv7YI7emc"},{"cell_type":"code","source":["# Load pre-trained model tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize text:\n","max_len = 1024\n","all_text = df_all_x#[0:2000]\n","all_y = df_all_y#[0:2000]\n","all_input_ids = [tokenizer.encode(doc, add_special_tokens=True, max_length=max_len, truncation=True) for doc in all_text]\n","all_input_ids = tf.keras.preprocessing.sequence.pad_sequences(all_input_ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","\n","X_temp, X_test, Y_temp, Y_test = train_test_split(all_input_ids, all_y, test_size=0.2)\n","X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512,"referenced_widgets":["31bf662159534d2c9a49aa06420767d5","7ed9a2f19fd742b38824bf93a6c07b13","1f2798dd877b4beb85ddcbb9797e3336","c5a5e21146e240979ebdc1b739ec612c","db9fb7c56cb140bda4397a30ed1758d1","91feea9102e74341a8532aa7d93ef545","c3dc17b0cd4b4eb3aed4dc352538fa9f","61ee781e3d7a4d278cded19a94ccf64d","7e3a86659e844c89a31c8795e036a7bc","12608b073c6f43088a87b83a0e6ac872","93c847384dbc45a0b4b120480625d231","b0ce395e56bb44c7bae88c6141a8b8ec","fd9073c7c8fa42b3805f8a76e0827e70","e78d50ef28f542469ec2d0365f781445","15abb6640f5c42cc843fc38253403304","5c949b0d2afb4592960133bef85f5712","d790f094df244234a97195539b5aa2e0","7522d8979aef41d4a3c8585efdde8dfc","c97ebbaf1b3841bd8aba291c95f4132a","62c0e5b7b3884851947111bdc398fa6f","99ec7bfc97e6480f8360177d8f4bfe3c","5720ff280ba04d03a62d4bbdc63c1ece","91dd10265cf349cb99cf5ba8738f2243","63f82c72fcaf4f248307b336284ce132","0f9d3d3c50fa405bb19bb7cec9aaacfa","1d3c91a93f384a1cbf56300e27cf9856","7c77e271335a454ab3bbbb505ec847aa","6a6eca85a4db4693bf362bf5611e7a20","66408f1825b244b39a872c1e5efcbfb2","e464d1d0b26c457798aea1f6020bb412","390ea83c539c4f67894b7bdc957251df","97bf472e203d4eff8916691aa2456cb5","2a7e362de9d04454888e47366e67bd0c"]},"id":"GYbGdN0w4USc","executionInfo":{"status":"error","timestamp":1688117513861,"user_tz":-120,"elapsed":73731,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"54a25531-0b5a-4aec-facd-e5241f608956"},"id":"GYbGdN0w4USc","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31bf662159534d2c9a49aa06420767d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ce395e56bb44c7bae88c6141a8b8ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91dd10265cf349cb99cf5ba8738f2243"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-c4e8a344b19b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all_x\u001b[0m\u001b[0;31m#[0:2000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all_y\u001b[0m\u001b[0;31m#[0:2000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mall_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mall_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-c4e8a344b19b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all_x\u001b[0m\u001b[0;31m#[0:2000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all_y\u001b[0m\u001b[0;31m#[0:2000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mall_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mall_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 method).\n\u001b[1;32m   2331\u001b[0m         \"\"\"\n\u001b[0;32m-> 2332\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2333\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2738\u001b[0m         )\n\u001b[1;32m   2739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2740\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2741\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             )\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             ]\n\u001b[1;32m    513\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescaped_special_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\")|\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"(.+?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["policy = Policy('mixed_float16')\n","set_global_policy(policy)"],"metadata":{"id":"o2PgSZNJRcG5"},"id":"o2PgSZNJRcG5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_BERT = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","model_BERT.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","model_BERT.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399,"referenced_widgets":["14aede70192c41ff9293ff9527a6a05e","bbfaf60cf1e747f89f8b57cea09ec15f","e09df3301b1942aca64a23f601db0d72","10209377dd87466da8a5b3b47c161856","b76147f8bf4a49d0870b5a2f98d69f5c","3b6e5281ed84462287c58f2a9c117160","570e3016663d46d29e1498bc3013d8f5","eb7b2cea26d144598c896988dd2a16fe","43a5d3f8799743c6ba59e0e808a500b0","b74c7d640b7c47829fde32dc53d7da44","6b2475df62d249c09b04d49269c6f995"]},"id":"QA_NTza6WX9K","executionInfo":{"status":"ok","timestamp":1688117528643,"user_tz":-120,"elapsed":10272,"user":{"displayName":"Peter Novak","userId":"17982974517295573360"}},"outputId":"7972d5e3-05ca-4d7e-9efe-b30e395d28eb"},"id":"QA_NTza6WX9K","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14aede70192c41ff9293ff9527a6a05e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bert (TFBertMainLayer)      multiple                  109482240 \n","                                                                 \n"," dropout_37 (Dropout)        multiple                  0         \n","                                                                 \n"," classifier (Dense)          multiple                  769       \n","                                                                 \n","=================================================================\n","Total params: 109,483,009\n","Trainable params: 109,483,009\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_BERT.fit(X_train, Y_train,\n","               validation_data=(X_val, Y_val),\n","               batch_size=16, epochs=10)\n","\n","model_BERT.save(path + './ECHR_model/model_bert__dataset_all')"],"metadata":{"id":"CVDiAt2IWfEZ"},"id":"CVDiAt2IWfEZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = [int(float((np.exp(x) / (1 + np.exp(x)))) > 0.5) for x in model_BERT.predict(X_test).logits]\n","print(accuracy_score(Y_test, y_pred))\n","print(f1_score(Y_test, y_pred, average='macro'))"],"metadata":{"id":"YLFX3Z7lAh6U"},"id":"YLFX3Z7lAh6U","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation of LR:"],"metadata":{"id":"VdrSlQFqtRV8"},"id":"VdrSlQFqtRV8"},{"cell_type":"code","source":["df_train_x = pd.read_pickle(path + \"ECHR_Dataset_clean/df_train_x.pkl\")\n","df_train_y = pd.read_pickle(path + \"ECHR_Dataset_clean/df_train_y.pkl\")\n","df_test_x  = pd.read_pickle(path + \"ECHR_Dataset_clean/df_test_x.pkl\")\n","df_test_y  = pd.read_pickle(path + \"ECHR_Dataset_clean/df_test_y.pkl\")"],"metadata":{"id":"x_j8JyKatT5n"},"id":"x_j8JyKatT5n","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert to 3000 component tSVD:\n","vec = TfidfVectorizer(ngram_range=(1, 2), min_df = 6, max_df = 0.9, dtype = np.float32)\n","bow_matrix_train = abs(vec.fit_transform(df_train_x))\n","bow_array_train = bow_matrix_train.toarray()\n","bow_matrix_test = vec.transform(df_test_x)\n","bow_array_test = bow_matrix_test.toarray()\n","\n","tsvd_algo = TruncatedSVD(algorithm = 'randomized', n_components = 3000)\n","tsvd_train = tsvd_algo.fit_transform(bow_matrix_train.asfptype())\n","bow_df_train = pd.DataFrame(data=tsvd_train)\n","\n","tsvd_test = tsvd_algo.transform(bow_array_test)\n","bow_df_test = pd.DataFrame(data=tsvd_test)"],"metadata":{"id":"z0U-cIP2tZmP"},"id":"z0U-cIP2tZmP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hyperparameter_tuning(model, params, x_train, y_train):\n","    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","    clf = RandomizedSearchCV(model(), params, cv=kfold, n_iter=100, n_jobs=-2, random_state=42, verbose=1)\n","    search = clf.fit(x_train, y_train)\n","\n","    return search.best_params_, search.best_estimator_\n","\n","def run_model_on_dataset(x_train, y_train):\n","    best_params, best_model = hyperparameter_tuning(\n","        LogisticRegression, {\n","            'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n","            'penalty': ['l1', 'l2'],\n","            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga', 'sag'],\n","            }, x_train, y_train)\n","\n","    print(\"Best Parameters:\", best_params)\n","\n","    return best_model\n","\n","best_mod = run_model_on_dataset(bow_df_train, df_train_y)"],"metadata":{"id":"-eBpTCHOtZjw"},"id":"-eBpTCHOtZjw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get tsvd components as lin combo:\n","tsvd_components = tsvd_algo.components_\n","# Get coefs of LR:\n","coefficients = best_mod.coef_[0]\n","# Get fature contribution to predictions:\n","feature_contributions = np.dot(coefficients, tsvd_components)\n","# Get corresponding bi-grams:\n","feature_names = vec.get_feature_names_out()\n","# Feature importance dict:\n","feature_importance_dict = dict(zip(feature_names, feature_contributions))\n","# Most important features:\n","sorted_feature_importance_dict = {k: v for k, v in sorted(feature_importance_dict.items(), key=lambda item: abs(item[1]), reverse=True)}"],"metadata":{"id":"SFEphh6FtZg3"},"id":"SFEphh6FtZg3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def highlight_text_html(text, importance_dict):\n","    max_imp = max(feature_importance_dict.values())\n","    min_imp = min(feature_importance_dict.values())\n","\n","    words = text.split()\n","    i = 0\n","    result = '<html><body><p>'\n","    while i < len(words):\n","        # Check 2-gram\n","        if i < len(words) - 1 and ' '.join(words[i:i+2]) in importance_dict:\n","            ngram = ' '.join(words[i:i+2])\n","            i += 2\n","        # Check 1-gram\n","        elif words[i] in importance_dict:\n","            ngram = words[i]\n","            i += 1\n","        # No n-gram found, move to next word\n","        else:\n","            result += words[i] + ' '\n","            i += 1\n","            continue\n","\n","        # Calculate color based on score\n","        score = importance_dict[ngram]\n","        norm_score = (score - min_imp) / (max_imp - min_imp)\n","        if norm_score < 0.4 or norm_score > 0.6:\n","            rgb = matplotlib.colors.rgb2hex(cm.coolwarm(norm_score)[:3])\n","            # Append highlighted n-gram to result\n","            result += f'<span style=\"color: {rgb}\">{ngram}</span> '\n","        else:\n","            result += ngram + ' '\n","\n","    result += '</p></body></html>'\n","    return result\n","\n","html_text = highlight_text_html(df_train_x[2916], feature_importance_dict)\n","\n","# Write the html text to a file\n","with open(path + 'highlighted_text.html', 'w') as f:\n","    f.write(html_text)"],"metadata":{"id":"O5j2tSn-toMT"},"id":"O5j2tSn-toMT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_importance_df = {key: value for key, value in feature_importance_dict.items() if not re.search(r'\\d', key)}\n","feature_importance_df = pd.DataFrame(list(feature_importance_df.items()), columns=['Feature', 'Importance'])\n","feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n","\n","# Get the top 20 positive and top 20 negative features\n","top_pos = feature_importance_df.head(20)\n","top_neg = feature_importance_df.tail(20)\n","\n","# Create subplots\n","sns.set(font_scale=1.2)\n","fig, axs = plt.subplots(ncols=2, figsize=(14, 6))\n","\n","# Plot the top 20 positive features\n","sns.barplot(x='Importance', y='Feature', data=top_pos, ax=axs[0], palette='viridis')\n","axs[0].set_title('Top 20 Positive Features')\n","\n","# Plot the top 20 negative features\n","sns.barplot(x='Importance', y='Feature', data=top_neg, ax=axs[1], palette='viridis')\n","axs[1].set_title('Top 20 Negative Features')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"qtlDHL0OtoJQ"},"id":"qtlDHL0OtoJQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate CNN:"],"metadata":{"id":"Espcy5N1tzrr"},"id":"Espcy5N1tzrr"},{"cell_type":"code","source":["unique_y = [\"violation\", \"no-violation\"]\n","explainer = lime_text.LimeTextExplainer(class_names=unique_y, verbose=True)\n","\n","def predict_proba(arr):\n","  list_tokenized_ex = tokenizer.texts_to_sequences(arr)\n","  token_ex = pad_sequences(list_tokenized_ex, maxlen=max_len)\n","  pred = model_CNN.predict(token_ex)\n","\n","  l = []\n","  for i in pred:\n","    l.append(np.array([1-i[0], i[0]]))\n","  return np.array(l)"],"metadata":{"id":"P98wDDq0t1v1"},"id":"P98wDDq0t1v1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["explainer.explain_instance(df_train_x.iloc[6071], predict_proba).show_in_notebook(text=True)"],"metadata":{"id":"VXbe3-mrt9w7"},"id":"VXbe3-mrt9w7","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["QhtHKo8oQZVD","S6KI8pRgzkqK","VdrSlQFqtRV8","Espcy5N1tzrr"],"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"31bf662159534d2c9a49aa06420767d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ed9a2f19fd742b38824bf93a6c07b13","IPY_MODEL_1f2798dd877b4beb85ddcbb9797e3336","IPY_MODEL_c5a5e21146e240979ebdc1b739ec612c"],"layout":"IPY_MODEL_db9fb7c56cb140bda4397a30ed1758d1"}},"7ed9a2f19fd742b38824bf93a6c07b13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91feea9102e74341a8532aa7d93ef545","placeholder":"‚Äã","style":"IPY_MODEL_c3dc17b0cd4b4eb3aed4dc352538fa9f","value":"Downloading (‚Ä¶)solve/main/vocab.txt: 100%"}},"1f2798dd877b4beb85ddcbb9797e3336":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61ee781e3d7a4d278cded19a94ccf64d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e3a86659e844c89a31c8795e036a7bc","value":231508}},"c5a5e21146e240979ebdc1b739ec612c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12608b073c6f43088a87b83a0e6ac872","placeholder":"‚Äã","style":"IPY_MODEL_93c847384dbc45a0b4b120480625d231","value":" 232k/232k [00:00&lt;00:00, 554kB/s]"}},"db9fb7c56cb140bda4397a30ed1758d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91feea9102e74341a8532aa7d93ef545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3dc17b0cd4b4eb3aed4dc352538fa9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61ee781e3d7a4d278cded19a94ccf64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e3a86659e844c89a31c8795e036a7bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12608b073c6f43088a87b83a0e6ac872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93c847384dbc45a0b4b120480625d231":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0ce395e56bb44c7bae88c6141a8b8ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd9073c7c8fa42b3805f8a76e0827e70","IPY_MODEL_e78d50ef28f542469ec2d0365f781445","IPY_MODEL_15abb6640f5c42cc843fc38253403304"],"layout":"IPY_MODEL_5c949b0d2afb4592960133bef85f5712"}},"fd9073c7c8fa42b3805f8a76e0827e70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d790f094df244234a97195539b5aa2e0","placeholder":"‚Äã","style":"IPY_MODEL_7522d8979aef41d4a3c8585efdde8dfc","value":"Downloading (‚Ä¶)okenizer_config.json: 100%"}},"e78d50ef28f542469ec2d0365f781445":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c97ebbaf1b3841bd8aba291c95f4132a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62c0e5b7b3884851947111bdc398fa6f","value":28}},"15abb6640f5c42cc843fc38253403304":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ec7bfc97e6480f8360177d8f4bfe3c","placeholder":"‚Äã","style":"IPY_MODEL_5720ff280ba04d03a62d4bbdc63c1ece","value":" 28.0/28.0 [00:00&lt;00:00, 2.36kB/s]"}},"5c949b0d2afb4592960133bef85f5712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d790f094df244234a97195539b5aa2e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7522d8979aef41d4a3c8585efdde8dfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c97ebbaf1b3841bd8aba291c95f4132a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62c0e5b7b3884851947111bdc398fa6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99ec7bfc97e6480f8360177d8f4bfe3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5720ff280ba04d03a62d4bbdc63c1ece":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91dd10265cf349cb99cf5ba8738f2243":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63f82c72fcaf4f248307b336284ce132","IPY_MODEL_0f9d3d3c50fa405bb19bb7cec9aaacfa","IPY_MODEL_1d3c91a93f384a1cbf56300e27cf9856"],"layout":"IPY_MODEL_7c77e271335a454ab3bbbb505ec847aa"}},"63f82c72fcaf4f248307b336284ce132":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a6eca85a4db4693bf362bf5611e7a20","placeholder":"‚Äã","style":"IPY_MODEL_66408f1825b244b39a872c1e5efcbfb2","value":"Downloading (‚Ä¶)lve/main/config.json: 100%"}},"0f9d3d3c50fa405bb19bb7cec9aaacfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e464d1d0b26c457798aea1f6020bb412","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_390ea83c539c4f67894b7bdc957251df","value":570}},"1d3c91a93f384a1cbf56300e27cf9856":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97bf472e203d4eff8916691aa2456cb5","placeholder":"‚Äã","style":"IPY_MODEL_2a7e362de9d04454888e47366e67bd0c","value":" 570/570 [00:00&lt;00:00, 46.8kB/s]"}},"7c77e271335a454ab3bbbb505ec847aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a6eca85a4db4693bf362bf5611e7a20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66408f1825b244b39a872c1e5efcbfb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e464d1d0b26c457798aea1f6020bb412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390ea83c539c4f67894b7bdc957251df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97bf472e203d4eff8916691aa2456cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a7e362de9d04454888e47366e67bd0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14aede70192c41ff9293ff9527a6a05e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbfaf60cf1e747f89f8b57cea09ec15f","IPY_MODEL_e09df3301b1942aca64a23f601db0d72","IPY_MODEL_10209377dd87466da8a5b3b47c161856"],"layout":"IPY_MODEL_b76147f8bf4a49d0870b5a2f98d69f5c"}},"bbfaf60cf1e747f89f8b57cea09ec15f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6e5281ed84462287c58f2a9c117160","placeholder":"‚Äã","style":"IPY_MODEL_570e3016663d46d29e1498bc3013d8f5","value":"Downloading model.safetensors: 100%"}},"e09df3301b1942aca64a23f601db0d72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb7b2cea26d144598c896988dd2a16fe","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43a5d3f8799743c6ba59e0e808a500b0","value":440449768}},"10209377dd87466da8a5b3b47c161856":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74c7d640b7c47829fde32dc53d7da44","placeholder":"‚Äã","style":"IPY_MODEL_6b2475df62d249c09b04d49269c6f995","value":" 440M/440M [00:00&lt;00:00, 486MB/s]"}},"b76147f8bf4a49d0870b5a2f98d69f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6e5281ed84462287c58f2a9c117160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570e3016663d46d29e1498bc3013d8f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb7b2cea26d144598c896988dd2a16fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a5d3f8799743c6ba59e0e808a500b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b74c7d640b7c47829fde32dc53d7da44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b2475df62d249c09b04d49269c6f995":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}